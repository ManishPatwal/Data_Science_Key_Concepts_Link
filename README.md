# Data_Science_Key_Concepts_Link
This repo contains link of Important Data Science Articles, Concepts and Approaches from around the web.

**PCA**
https://towardsdatascience.com/https-medium-com-abdullatif-h-dimensionality-reduction-for-dummies-part-1-a8c9ec7b7e79



 **10 Most Important Alogirthms**
 https://link.medium.com/lbPxnl2J8Q
 **Tuning Machine Learning Models Using the Caret R Package**
https://machinelearningmastery.com/tuning-machine-learning-models-using-the-caret-r-package/

**Glossary ML &DS **
https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/


**Developing R Packages**
https://www.youtube.com/watch?v=NviTl4UJGt0

**https://awesome-r.com/**
**Machine Learning**
https://www.analyticsvidhya.com/blog/2017/09/common-machine-learning-algorithms/

**Suport Vector Machine**
https://www.analyticsvidhya.com/blog/2017/09/understaing-support-vector-machine-example-code/
In geometry, a hyperplane is a subspace whose dimension is one less than that of its ambient space. If a space is 3-dimensional then its hyperplanes are the 2-dimensional planes, while if the space is 2-dimensional, its hyperplanes are the 1-dimensional lines.
If you have a classification problem, i.e., discrete label to predict, you can use C-classification and nu-classification.

If you have a regression problem, i.e., continuous number to predict, you can use eps-regression and nu-regression.

If you only have one class of the data, i.e., normal behavior, and want to detect outliers.  one-classification.

**Tree Based Modelling from Scratch**
https://www.analyticsvidhya.com/blog/2016/04/complete-tutorial-tree-based-modeling-scratch-in-python/

**Tidy Text Data in R**
https://www.tidytextmining.com/preface.html
https://www.youtube.com/watch?v=0poJP8WQxew

**Creating Packages**
Caret Package in R

https://www.analyticsvidhya.com/blog/2016/12/practical-guide-to-implement-machine-learning-with-caret-package-in-r-with-practice-problem/https://www.analyticsvidhya.com/blog/2016/12/practical-guide-to-implement-machine-learning-with-caret-package-in-r-with-practice-problem/

**Shiny App Tutorial**
https://youtu.be/_0ORRJqctHE
https://www.analyticsvidhya.com/blog/2016/10/creating-interactive-data-visualization-using-shiny-app-in-r-with-examples/

**LEAFLET & SHINY INTERACTIVE TUTORIAL**
https://www.datascience.com/blog/beginners-guide-to-shiny-and-leaflet-for-interactive-mapping

##MATHS

How do data scientists use statistics? by William Chen https://www.quora.com/How-do-data-scientists-use-statistics/answer/William-Chen-6?share=7310896c&srid=nLpS


What is the best way to learn basic statistics besides taking a college course? by Alexey Grigorev https://www.quora.com/What-is-the-best-way-to-learn-basic-statistics-besides-taking-a-college-course/answer/Alexey-Grigorev?share=f8b0af74&srid=nLpS


Linear algebra
https://www.analyticsvidhya.com/blog/2017/05/comprehensive-guide-to-linear-algebra/

Linear Regression/Lasso Regression /Ridge 
https://www.analyticsvidhya.com/blog/2017/06/a-comprehensive-guide-for-linear-ridge-and-lasso-regression/

##Other Key Concepts
CPU vs GPU
https://www.analyticsvidhya.com/blog/2017/05/gpus-necessary-for-deep-learning/

**Deep Learning **

Neural network

https://www.analyticsvidhya.com/blog/2016/03/introduction-deep-learning-fundamentals-neural-networks/

Classification Methods Essentials
http://www.sthda.com/english/articles/36-classification-methods-essentials/149-penalized-logistic-regression-essentials-in-r-ridge-lasso-and-elastic-net/

Mathematics
information theory
https://en.wikipedia.org/wiki/Entropy_(information_theory)


Penalized Logistic Regression Essentials in R: Ridge, Lasso and Elastic Net

Penalized logistic regression imposes a penalty to the logistic model for having too many variables. This results in shrinking the coefficients of the less contributive variables toward zero. This is also known as regularization.

The most commonly used penalized regression include:

ridge regression: variables with minor contribution have their coefficients close to zero. However, all the variables are incorporated in the model. This is useful when all variables need to be incorporated in the model according to domain knowledge.
lasso regression: the coefficients of some less contributive variables are forced to be exactly zero. Only the most significant variables are kept in the final model.
elastic net regression: the combination of ridge and lasso regression. It shrinks some coefficients toward zero (like ridge regression) and set some coefficients to exactly zero (like lasso regression)
https://towardsdatascience.com/regularization-in-machine-learning-76441ddcf99a

**Bagging vs Bootstrapping**
The big difference between bagging and validation techniques is that bagging averages models (or predictions of an ensemble of models) in order to reduce the variance the prediction is subject to while resampling validation such as cross validation and out-of-bootstrap validation evaluate a number of surrogate models assuming that they are equivalent (i.e. a good surrogate) for the actual model in question which is trained on the whole data set.

Bagging uses bootstrapped subsets (i.e. drawing with replacement of the original data set) of training data to generate such an ensemble but you can also use ensembles that are produced by drawing without replacement, i.e. cross validation: 


http://www.robots.ox.ac.uk/~az/lectures/ml/lect4.pdf

**Bias Vs Variance**
https://towardsdatascience.com/balancing-bias-and-variance-to-control-errors-in-machine-learning-16ced95724db

**WEB APIS in R**
https://www.youtube.com/watch?v=lV3u6Dc93T0

**Mathematics**
In geometry, a hyperplane is a subspace whose dimension is one less than that of its ambient space. If a space is 3-dimensional then its hyperplanes are the 2-dimensional planes, while if the space is 2-dimensional, its hyperplanes are the 1-dimensional lines.

**Sigmoid function**

**Super Data Science**
https://www.superdatascience.com/machine-learning/

**SVM RADIAL**
https://www.r-bloggers.com/radial-kernel-support-vector-classifier/

**ENSEMBLE MODELS IN R**
https://machinelearningmastery.com/machine-learning-ensembles-with-r/

**https://datascienceplus.com/extreme-gradient-boosting-with-r/**

**Out of Sample Error**
https://www.youtube.com/watch?v=uswmGsGmDZc

**Ensemble Learning**
Stack Mutiple Models
Combine Models for Prediction
https://www.datacamp.com/community/tutorials/ensemble-r-machine-learning

**Super Learner Package in R**
https://www.datacamp.com/community/tutorials/ensemble-r-machine-learning

**Models for Classification**
https://deepsense.ai/extreme-gradient-boosting-vs-random-forest-and-the-caret-package-for-r/

**Ensemble Model**
What are Bagging, Boosting and Stacking?
https://www.analyticsvidhya.com/blog/2015/09/questions-ensemble-modeling/
https://www.analyticsvidhya.com/blog/2015/08/introduction-ensemble-learning/


**Making Predictions over HTTP with R**
https://raybuhr.github.io/2017/10/making-predictions-over-http/

**APM BOOK EXCERCISES**
https://github.com/topepo/APM_Exercises

**10 R packages I wish**
http://blog.yhat.com/posts/10-R-packages-I-wish-I-knew-about-earlier.html

**Processing and Analyzing Financial Data with R**
https://msperlin.github.io/pafdR/preface.html

**Processing and Analyzing Financial Data with R**
https://www.analyticsvidhya.com/blog/2016/03/introduction-deep-learning-fundamentals-neural-networks/

**Building a drone in 50 lines of code**
https://medium.com/nanonets/how-i-built-a-self-flying-drone-to-track-people-in-under-50-lines-of-code-7485de7f828e

**Bias-Variance Tradeoff:**
https://www.kdnuggets.com/2016/08/bias-variance-tradeoff-overview.html


**Web scraping**
https://www.analyticsvidhya.com/blog/2017/03/beginners-guide-on-web-scraping-in-r-using-rvest-with-hands-on-knowledge/


https://github.com/amrrs/oneplus_amz_availability

**NEURAL NETWORK BOOKS**
http://neuralnetworksanddeeplearning.com/chap1.html
http://colah.github.io/





